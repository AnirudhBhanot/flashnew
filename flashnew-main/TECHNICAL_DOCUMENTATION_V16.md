# FLASH Technical Documentation V16 - Realistic Models with AI Integration

**Last Updated**: June 7, 2025  
**Version**: 16.2 (AI-Enhanced with Personalized Recommendations)

## Overview

FLASH is an AI-powered startup assessment platform that provides **honest, realistic predictions** about startup success using machine learning. The system has evolved from unrealistic synthetic models to truly realistic models that acknowledge the inherent uncertainty in early-stage prediction.

### ðŸš€ New in V16.2: Personalized AI Recommendations
- **Context-Aware Recommendations**: LLM generates advice specific to each startup's metrics
- **CAMP-Aligned Guidance**: First recommendation always addresses weakest area
- **Fixed Data Flow**: userInput now properly passed to LLM for personalization
- **Enhanced Prompts**: Detailed rules prevent generic advice
- **Working What-If Analysis**: Realistic predictions with quantified impacts

### Recent Fixes (June 7, 2025)
- **Authentication**: Removed API key header for development (DISABLE_AUTH=true)
- **Data Validation**: Fixed all field transformations (e-commerceâ†’ecommerce, AI/MLâ†’deeptech)
- **LLM Context**: Added userInput to enrichedData for proper personalization
- **Prompt Engineering**: Enhanced to identify weakest areas and reference specific metrics

## Key Technical Evolution

### From Fantasy to Reality

1. **V1-V14**: Synthetic data, unrealistic 94-100% AUC
2. **V15**: Realistic data approach (72.7% AUC)  
3. **V16**: Production deployment with 50% AUC on truly realistic data

## Current System Architecture

### Models (Production V46 Realistic)

```
models/production_v46_realistic/
â”œâ”€â”€ dna_analyzer.pkl      # AUC: 0.489
â”œâ”€â”€ temporal_model.pkl    # AUC: 0.505
â”œâ”€â”€ industry_model.pkl    # AUC: 0.504
â”œâ”€â”€ ensemble_model.pkl    # AUC: 0.499
â””â”€â”€ feature_columns.pkl   # 85 features
```

### Performance Metrics

- **Average AUC**: 0.499 (~50%)
- **True Positive Rate**: 18.5%
- **True Negative Rate**: 81.8%
- **Overall Accuracy**: 84% (mostly predicting failure)

### Why 50% AUC is Actually Good

1. **Honest Assessment**: Shows true difficulty of early-stage prediction
2. **No Overfitting**: Models aren't memorizing fake patterns
3. **Academic Alignment**: Matches research on startup prediction
4. **Business Value**: Even 18.5% TPR means catching 1 in 5 unicorns

## Dataset Characteristics

### Realistic Training Data (100K Companies)

```python
# Distribution
- Pre-seed: 35% (35,000 companies)
- Seed: 25% (25,000 companies)
- Series A: 20% (20,000 companies)
- Series B+: 20% (20,000 companies)

# Key Realism Features
- 85% of pre-seed have $0 revenue
- Average pre-seed team: 2.1 people
- 51% of pre-seed have 0 customers
- 16% overall success rate
- 25% missing data for early stages
```

### Pre-Seed Characteristics

```python
# Revenue Distribution
- 84.9% have $0
- 15.1% have $1-100k
- 0% have >$100k

# Team Size
- 84.6% have 1-3 people
- 15.4% have 4-6 people
- 0% have >10 people

# Product Stage
- 40.3% at idea stage
- 34.6% at prototype
- 20.0% at MVP
- 5.1% at beta
```

## LLM Integration (Updated V16.2)

### DeepSeek API Configuration

```python
# In .env
DEEPSEEK_API_KEY=sk-f68b7148243e4663a31386a5ea6093cf
LLM_CACHE_TTL=3600
DISABLE_AUTH=true  # For development
```

### Prompt Engineering for Personalization

The LLM integration uses detailed prompts with strict rules to ensure personalized, context-specific recommendations:

```python
# Key prompt components
1. Context injection: All startup metrics embedded in prompt
2. Weakest area identification: Automatically calculated and emphasized
3. Anti-generic rules: "DO NOT give generic advice"
4. Structured output: JSON format with specific fields
5. Quantified impact: Must include measurable outcomes
```

#### Example Prompt Structure
```python
f"""You are an expert startup advisor analyzing a {stage} {sector} company.

CAMP Framework Scores (0-100 scale):
- Capital: {capital}% - Financial health, runway, burn efficiency
- Advantage: {advantage}% - Competitive moat, differentiation, IP
- Market: {market}% - TAM, growth rate, market timing
- People: {people}% - Team experience, composition, advisors

WEAKEST AREA: {weakest_area} ({score}%)

Key Metrics:
- Annual Revenue: ${revenue:,.0f}
- Monthly Burn: ${burn:,.0f}
- Team Size: {team_size}
[...all other metrics...]

CRITICAL: Generate exactly 3 HIGHLY SPECIFIC recommendations:
1. First recommendation MUST address the weakest CAMP area
2. Be specific to their {sector} industry and {stage} stage
3. Reference their specific numbers and context
4. Make recommendations achievable within constraints

DO NOT give generic advice."""
```

### LLM Endpoints

#### 1. Status Check
```http
GET /api/analysis/status
Response: {
  "status": "operational",
  "model": "deepseek-chat",
  "cache_enabled": false
}
```

#### 2. Dynamic Recommendations (Fixed in V16.2)
```http
POST /api/analysis/recommendations/dynamic
Body: {
  "funding_stage": "seed",
  "sector": "saas",
  "scores": {
    "capital": 0.65,
    "advantage": 0.58,
    "market": 0.72,
    "people": 0.25  # Weakest area
  },
  "userInput": {  # CRITICAL: Now properly passed
    "annual_revenue_run_rate": 500000,
    "monthly_burn_usd": 80000,
    "team_size_full_time": 8,
    "years_experience_avg": 5
  }
}
Response: {
  "recommendations": [
    {
      "title": "Hire a seasoned SaaS VP of Engineering",
      "why": "The team's low experience (5 years) is critical...",
      "how": [
        "Allocate $150k/year from burn ($12.5k/month)",
        "Leverage advisor networks for referrals",
        "Structure equity at 1-2% to attract talent"
      ],
      "timeline": "8 weeks",
      "impact": "Improve engineering velocity by 30% within 3 months",
      "camp_area": "people"  # Addresses weakest area
    }
  ]
}
```

#### 3. What-If Analysis
```http
POST /api/analysis/whatif/dynamic
Body: {
  "startup_data": {...},
  "current_scores": {
    "capital": 0.55,
    "advantage": 0.44,
    "market": 0.63,
    "people": 0.27,  # Weakest area
    "success_probability": 0.52
  },
  "improvements": [
    {"id": "hire_vp", "description": "Hire VP Sales with enterprise SaaS experience"},
    {"id": "advisory", "description": "Add 3 industry advisors"}
  ]
}
Response: {
  "new_probability": {"value": 0.60, "lower": 0.55, "upper": 0.65},
  "new_scores": {
    "capital": 0.55,      # No change
    "advantage": 0.50,    # +0.06 (6% improvement)
    "market": 0.65,       # +0.02 (2% improvement)  
    "people": 0.45        # +0.18 (18% improvement)
  },
  "score_changes": {
    "capital": 0.0,
    "advantage": 0.06,
    "market": 0.02,
    "people": 0.18
  },
  "timeline": "3-6 months",
  "risks": [
    "VP hiring may take longer in competitive market",
    "Advisory board effectiveness depends on engagement"
  ],
  "priority": "hire_vp"
}
```

### Response Times
- **LLM Status**: 15-20 seconds (normal for DeepSeek)
- **Recommendations**: 15-20 seconds (with personalization)
- **What-If**: 15-20 seconds (with calculations)

## API Configuration

### Server Details

- **URL**: `http://localhost:8001`
- **Framework**: FastAPI
- **Models**: Loaded directly from pickles
- **Authentication**: Disabled in dev (`DISABLE_AUTH=true`)

### Key Endpoints

```bash
GET  /                    # API info
GET  /health             # Health check
POST /predict            # Make prediction
GET  /features           # Model features
GET  /config/{type}      # Configuration
```

### Prediction Request Example

```bash
curl -X POST "http://localhost:8001/predict" \
  -H "Content-Type: application/json" \
  -d '{
    "funding_stage": "pre_seed",
    "total_capital_raised_usd": 150000,
    "team_size_full_time": 2,
    "annual_revenue_run_rate": 0,
    ...
  }'
```

### Response Format

```json
{
  "success_probability": 0.347,
  "confidence_score": 0.5,
  "verdict": "PASS",
  "risk_level": "Medium Risk",
  "camp_analysis": {
    "capital": 0.45,
    "advantage": 0.45,
    "market": 0.47,
    "people": 0.53
  },
  "disclaimer": "Early-stage prediction is highly uncertain"
}
```

## Frontend Updates

### Key Changes in V16.2

1. **Fixed Data Transformations** (`HybridAnalysisPage.tsx`)
   ```typescript
   // Sector mappings
   'ai/ml' â†’ 'deeptech'
   'e-commerce' â†’ 'ecommerce'
   'health tech' â†’ 'healthtech'
   
   // Investor tier
   'tier1' â†’ 'tier_1'
   'tier2' â†’ 'tier_2'
   
   // Product stage
   'GA' â†’ 'launched'
   'general availability' â†’ 'launched'
   ```

2. **Removed Authentication Headers**
   ```typescript
   // Before
   headers: { 
     'Content-Type': 'application/json',
     'X-API-Key': API_CONFIG.API_KEY  // REMOVED
   }
   
   // After  
   headers: { 
     'Content-Type': 'application/json'
   }
   ```

3. **Added userInput to LLM Data**
   ```typescript
   const enrichedData = {
     funding_stage: transformedData.funding_stage,
     sector: transformedData.sector,
     scores: results.camp_analysis,
     verdict: results.verdict,
     userInput: startupData  // CRITICAL: Added for personalization
   };
   ```

## Model Training Process

### 1. Generate Realistic Dataset
```python
python3 create_realistic_dataset_100k.py
# Creates dataset with realistic pre-seed characteristics
```

### 2. Train Models
```python
python3 retrain_production_v46_realistic.py
# Trains 4 models with realistic expectations
```

### 3. Verify Performance
```python
python3 analyze_realistic_performance.py
# Should show ~50% AUC, not 95%+
```

## Troubleshooting

### Common Issues and Solutions (Updated June 7, 2025)

#### 1. 403 Forbidden Error
```bash
# Issue: Frontend sending API key when auth disabled
# Solution: Remove X-API-Key header from requests
headers: { 
  'Content-Type': 'application/json'
  // 'X-API-Key': API_CONFIG.API_KEY  // REMOVED
}
```

#### 2. 500 Validation Errors
```bash
# Common errors:
"sector must be one of [...] (got e_commerce)"
"investor_tier_primary must be one of [...] (got tier1)"

# Solution: Fixed in transformDataForAPI function
const sectorMap = {
  'ai/ml': 'deeptech',
  'e-commerce': 'ecommerce',
  'health tech': 'healthtech'
};
```

#### 3. Generic LLM Recommendations
```bash
# Issue: "recommendations are same for all results"
# Root cause: userInput not passed to LLM
# Solution: Add userInput to enrichedData
const enrichedData = {
  ...scores,
  userInput: startupData  # CRITICAL FIX
};
```

#### 4. LLM Response Times
```bash
# Normal: DeepSeek takes 15-20 seconds
# Check: tail -f api_server.log | grep "LLM"
# Alternative: Use static recommendations if timeout
```

### Debug Commands
```bash
# Check API health
curl http://localhost:8001/health

# Test LLM status (expect 15-20s response)
curl http://localhost:8001/api/analysis/status

# Monitor LLM context
tail -f api_server.log | grep "startup_data"
# Should see actual data, not "None None"

# Test personalized recommendations
python3 test_llm_integration.py
```

### Verifying Personalization

1. **Check LLM receives context**:
   ```bash
   grep "Generating dynamic recommendations" api_server.log
   # Should show sector and stage, not "None None"
   ```

2. **Verify recommendations address weakest area**:
   - First recommendation should target lowest CAMP score
   - Should reference specific metrics from startup

3. **Test different scenarios**:
   - Low people score â†’ hiring recommendations
   - High burn â†’ capital efficiency advice
   - No revenue â†’ customer acquisition focus

## Key Files for LLM Integration

1. **`llm_analysis.py`**: Core LLM engine with prompt templates
2. **`api_llm_endpoints.py`**: API endpoint handlers
3. **`HybridAnalysisPage.tsx`**: Frontend data transformation
4. **`test_llm_integration.py`**: Validation test suite

## Conclusion

The V16.2 realistic models with personalized AI integration represent a major improvement in both **integrity** and **utility**. The system now provides:

1. **Honest Predictions**: ~50% AUC reflects real uncertainty
2. **Personalized AI Insights**: Context-specific recommendations via DeepSeek
3. **CAMP-Aligned Guidance**: Always addresses weakest areas first
4. **Fixed Data Flow**: All field mappings and context passing working
5. **Production Ready**: Full error handling, monitoring, and testing

This positions FLASH as a trustworthy AND intelligent tool for startup assessment, combining realistic ML predictions with highly personalized AI insights that reference each startup's specific metrics and challenges.